{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to FedPredict","text":""},{"location":"#the-first-ever-plugin-for-federated-learning","title":"The first-ever plugin for Federated Learning!","text":"<p>FedPredict is a Federated Learning (FL) plugin designed to enhance existing FL solutions without requiring additional training or computational overhead. It enables personalization in standard algorithms such as FedAvg and FedYogi, boosting performance in scenarios with non-IID data.</p> <p>As a modular component, FedPredict operates exclusively during the prediction phase of FL and does not require any modifications to the training process.</p> <p>This project has been developed through a collaboration between the WISEMAP Lab (UFMG), H.IAAC Lab (UNICAMP), and NESPED Lab (UFV).</p>"},{"location":"#news","title":"News","text":"<p>Citations:</p> <p>August 25, 2025 - Data Shift Under Delayed Labeling in Multi-Model Federated Learning, Cl\u00e1udio G. S. Capanema; Fabr\u00edcio A. Silva; Leandro A. Villas; Antonio A. F. Loureiro.</p> <p>May 6, 2025 - ClusterPredict: Enhancing Federated Clustering by Combining Global and Local Parameters, Mingliang Ni and Chaochao Sun.</p> <p>March 1, 2024 - Adaptive client selection with personalization for communication efficient Federated Learning, Allan M. de Souza, Filipe Maciel, Joahannes B.D. da Costa, Luiz F. Bittencourt, Eduardo Cerqueira, Antonio A.F. Loureiro, and Leandro A. Villas.</p>"},{"location":"about/","title":"About","text":"<p>FedPredict is an open-source project freely available on Github under the BSD-3 license. The project is led by Cl\u00e1udio G. S. Capanema and has been developed across the laboratories WISEMAP (UFMG), H.IAAC (UNICAMP), and NESPED-Lab (UFV).</p>"},{"location":"about/#citing","title":"Citing","text":"<p>If FedPredict has been useful to you, please cite our papers.</p> <p>FedPredict: Combining Global and Local Parameters in the Prediction Step of Federated Learning (original paper):</p> <pre><code>@INPROCEEDINGS{capanema2023fedpredict,\n  author={Capanema, Cl\u00e1udio G. S. and de Souza, Allan M. and Silva, Fabr\u00edcio A. and Villas, Leandro A. and Loureiro, Antonio A. F.},\n  booktitle={2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, \n  title={FedPredict: Combining Global and Local Parameters in the Prediction Step of Federated Learning}, \n  year={2023},\n  volume={},\n  number={},\n  pages={17-24},\n  keywords={Federated learning;Computational modeling;Neural networks;Mathematical models;Internet of Things;Distributed computing;Personalized Federated Learning;Neural Networks;Federated Learning Plugin},\n  doi={10.1109/DCOSS-IoT58021.2023.00012}}\n</code></pre> <p>A Novel Prediction Technique for Federated Learning (extended journal paper):</p> <pre><code>@ARTICLE{capanema2025@novel,\n  author={Capanema, Cl\u00e1udio G. S. and de Souza, Allan M. and da Costa, Joahannes B. D. and Silva, Fabr\u00edcio A. and Villas, Leandro A. and Loureiro, Antonio A. F.},\n  journal={IEEE Transactions on Emerging Topics in Computing}, \n  title={A Novel Prediction Technique for Federated Learning}, \n  year={2025},\n  volume={13},\n  number={1},\n  pages={5-21},\n  keywords={Servers;Costs;Training;Downlink;Adaptation models;Computational modeling;Federated learning;Quantization (signal);Context modeling;Accuracy;Federated learning plugin;neural networks;personalized federated learning},\n  doi={10.1109/TETC.2024.3471458}}\n</code></pre> <p>A Modular Plugin for Concept Drift in Federated Learning (FedPredict-Dynamic):</p> <pre><code>@INPROCEEDINGS{capanema2024@modular,\n  author={Capanema, Cl\u00e1udio G. S. and Da Costa, Joahannes B. D. and Silva, Fabr\u00edcio A. and Villas, Leandro A. and Loureiro, Antonio A. F.},\n  booktitle={2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, \n  title={A Modular Plugin for Concept Drift in Federated Learning}, \n  year={2024},\n  volume={},\n  number={},\n  pages={101-108},\n  keywords={Training;Accuracy;Federated learning;Geology;Concept drift;Data models;Internet of Things;Concept Drift;Personalized Federated Learning;Federated Learning Plugin;Neural Networks},\n  doi={10.1109/DCOSS-IoT61029.2024.00024}}\n</code></pre>"},{"location":"components/","title":"Components","text":""},{"location":"components/#components","title":"Components","text":"<p>Our solution has two main components: FedPredict client and FedPredict server. Their objectives are described below:</p> Components Objective FedPredict Client Transfer the knowledge from the updated global model to the client's stale local model FedPredict server (optional) Compresses the updated global model parameters to further send to the clients. Used together with FedPredict client"},{"location":"flower_fedpredict/","title":"Flower + FedPredict","text":"<p>The list below contains FedPredict tutorials:</p> <ul> <li>Flower+Pytorch in Jupyter notebook: example of FedPredict client using Flower <code>simulation</code>.</li> <li>Flower+Pytorch project: example of FedPredict client using Flower and Docker.</li> </ul>"},{"location":"hello_fedpredict/","title":"Hello FedPredict","text":""},{"location":"hello_fedpredict/#toy-example-fedpredict-client","title":"Toy example - FedPredict Client","text":"<p>At the client-side, after receiving the global model parameters in the prediction state, apply FedPredict as follows:</p> <pre><code>    from fedpredict import fedpredict_client_torch\n\n    \"\"\"Client evaluation\"\"\"\n\n    t = 50 # current round\n    T = 100 # total number of rounds\n    nt = 3 # number of rounds since the last time the current client trained\n\n    # apply fedpredict\n    combinel_model = fedpredict_client_torch(local_model=local_model, \n                                             global_model=global_model, \n                                             t=t, \n                                             T=T, \n                                             nt=nt)\n    # Use the combined model to perform predictions over the input data\n    y_hat = combined_model(X_test)\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>FedPredict is compatible with Python \u2265 3.8 and has been tested on the latest versions of Ubuntu. With your virtual environment activated, if you are using PyTorch, you can install FedPredict from PyPI by running the following command:</p> <pre><code>    pip install fedpredict[torch]\n</code></pre>"},{"location":"installation/#fl-requirements","title":"FL requirements","text":"<p>In general, if your solution shares structural similarities with FedAvg, then FedPredict is ready to be integrated. The requirements are outlined below:</p> Requirement Description Sharing all layers Clients must upload all model layers at each round so that the server can aggregate a global model, which can then be directly utilized by any new client\u2014similar to the standard FedAvg approach. Same model structure The layers of the global and local models must have matching shapes to enable proper parameter combination. Predicting using the combined model On the client side, the original method must be flexible enough to perform inference using the combined model; otherwise, the plugin will have no effect."},{"location":"projects/","title":"Projects","text":"<p>FedPredict is used in the following projects (updating):</p> <ul> <li>FL-H.IAAC: this project is characterized by the use of \"Flower + FedPredict\". Additionally, it adapts Flower to run Multi-model Federated Learning.</li> <li>PFlib (it will be available soon).</li> </ul>"},{"location":"why_fedpredict/","title":"Why FedPredict?","text":"<p>It is better working with the prediction stage. See the comparison below!</p> <p></p>"},{"location":"why_fedpredict/#how-does-it-work","title":"How does it work?","text":"<p>FedPredict intelligently combines global and local model parameters, assigning dynamic weights to each based on several factors.  These factors include the evolution level (el) of the global model, the update level (ul) of the local model, and the similarity (s) between previously seen data (i.e., data used in prior training) and newly acquired data. Using this adaptive combination, the client generates a personalized model, which is then used for prediction on validation or test data.</p> <p></p>"},{"location":"why_fedpredict/#benefits","title":"Benefits","text":"<p>The list of benefits of the plugin is as follows:</p> <ol> <li>High performance: Achieves strong performance in heterogeneous data environments.</li> <li>High efficiency for FL: Maintains high performance even with reduced training.</li> <li>Data shift-awareness: FedPredict enables near-instant adaptation to new scenarios in the presence of concept drift.</li> <li>Task independent: Can be applied to any type of deep neural network task.</li> <li>Easy to use and modular: No modifications are required in the training phase of your FL solution.</li> <li>Lightweight: Built from simple, efficient operations.</li> <li>Low downlink communication cost: The FedPredict server compresses global model parameters to reduce communication overhead.</li> </ol> <p>Just plug and play!</p>"}]}