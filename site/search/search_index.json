{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to FedPredict The very first Federated Learning Plugin! FedPredict is a personalization plugin for Federated Learning (FL) methods. It allows clients to collaboratively learn from each other without losing personalization in the local data. How it works? FedPredict intelligently combines global and local model parameters. In this process, it assigns more or less weight to each type of parameter according to various factors, such as the evolution level (el) of the global model, the update level (ul) of the local model, and the similarity (s) between the old data (i.e., the one in which the model was previously trained) and the recently acquired data). Then, the client uses the combined model to make predictions over the test/val data. Benefits The list of benefits of the plugin as listed as follows: High accuracy : it pushes up FL accuracy without requiring additional training! Support for dynamic data : it is designed for stationary and non-stationary non-IID data. Concept drift : FedPredict makes the model almost instantly adapt to the new scenario when concept drift occurs. Task independent : apply FedPredict for any type of deep neural network task. Easy to use : no modifications are necessary in the training stage of your solution! Low computational cost : it is composed of simple operations. Just plug and play! Installation FedPredict is compatible with Python>=3.8 and is tested on the latest versions of Ubuntu. With your virtual environment opened, if you are using torch type the following command to install FedPredict from Pypi: pip install fedpredict[torch] If you are using Flower for FL simulation, type: pip install fedpredict[flwr] FL requirements In general, if your solution shares some level of similarity with FedAvg, then FedPredict is ready to use. The requirements are described as follows: Sharing all layers . The clients have to upload all model layers at every round so the server can aggregate a global model that can be directly leveraged by a new client, as in FedAvg. Same model structure . The layers of the global and local models have to have the same shape to allow the combination of parameters. Predicting using the combined model . On the client side, the original method has to be flexible enough to make predictions based on the combined model; otherwise, the plugin will have no effect.","title":"Home"},{"location":"#welcome-to-fedpredict","text":"","title":"Welcome to FedPredict"},{"location":"#the-very-first-federated-learning-plugin","text":"FedPredict is a personalization plugin for Federated Learning (FL) methods. It allows clients to collaboratively learn from each other without losing personalization in the local data.","title":"The very first Federated Learning Plugin!"},{"location":"#how-it-works","text":"FedPredict intelligently combines global and local model parameters. In this process, it assigns more or less weight to each type of parameter according to various factors, such as the evolution level (el) of the global model, the update level (ul) of the local model, and the similarity (s) between the old data (i.e., the one in which the model was previously trained) and the recently acquired data). Then, the client uses the combined model to make predictions over the test/val data.","title":"How it works?"},{"location":"#benefits","text":"The list of benefits of the plugin as listed as follows: High accuracy : it pushes up FL accuracy without requiring additional training! Support for dynamic data : it is designed for stationary and non-stationary non-IID data. Concept drift : FedPredict makes the model almost instantly adapt to the new scenario when concept drift occurs. Task independent : apply FedPredict for any type of deep neural network task. Easy to use : no modifications are necessary in the training stage of your solution! Low computational cost : it is composed of simple operations. Just plug and play!","title":"Benefits"},{"location":"#installation","text":"FedPredict is compatible with Python>=3.8 and is tested on the latest versions of Ubuntu. With your virtual environment opened, if you are using torch type the following command to install FedPredict from Pypi: pip install fedpredict[torch] If you are using Flower for FL simulation, type: pip install fedpredict[flwr]","title":"Installation"},{"location":"#fl-requirements","text":"In general, if your solution shares some level of similarity with FedAvg, then FedPredict is ready to use. The requirements are described as follows: Sharing all layers . The clients have to upload all model layers at every round so the server can aggregate a global model that can be directly leveraged by a new client, as in FedAvg. Same model structure . The layers of the global and local models have to have the same shape to allow the combination of parameters. Predicting using the combined model . On the client side, the original method has to be flexible enough to make predictions based on the combined model; otherwise, the plugin will have no effect.","title":"FL requirements"},{"location":"about/","text":"About FedPredict is an open-source project freely available on Github under the BSD-3 license. This project has been developed in the laboratories WISEMAP (UFMG) and H.IAAC (UNICAMP). Citing If FedPredict has been useful to you, please cite our paper . The BibTeX is presented as follows: @inproceedings{capanema2023fedpredict, title={FedPredict: Combining Global and Local Parameters in the Prediction Step of Federated Learning}, author={Capanema, Cl{\\'a}udio GS and de Souza, Allan M and Silva, Fabr{\\'\\i}cio A and Villas, Leandro A and Loureiro, Antonio AF}, booktitle={2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, pages={17--24}, year={2023}, doi={https://doi.org/10.1109/DCOSS-IoT58021.2023.00012}, organization={IEEE} }","title":"About"},{"location":"about/#about","text":"FedPredict is an open-source project freely available on Github under the BSD-3 license. This project has been developed in the laboratories WISEMAP (UFMG) and H.IAAC (UNICAMP).","title":"About"},{"location":"about/#citing","text":"If FedPredict has been useful to you, please cite our paper . The BibTeX is presented as follows: @inproceedings{capanema2023fedpredict, title={FedPredict: Combining Global and Local Parameters in the Prediction Step of Federated Learning}, author={Capanema, Cl{\\'a}udio GS and de Souza, Allan M and Silva, Fabr{\\'\\i}cio A and Villas, Leandro A and Loureiro, Antonio AF}, booktitle={2023 19th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, pages={17--24}, year={2023}, doi={https://doi.org/10.1109/DCOSS-IoT58021.2023.00012}, organization={IEEE} }","title":"Citing"},{"location":"api_reference_tf/","text":"","title":"TensorFlow"},{"location":"api_reference_torch/","text":"Components FedPredict has three main components: Method Description Return Location fedpredict_client_torch / fedpredict_client_tf Combines global and local parameters. Used when data is non-ID either stationary or non-stationary. The combined model of type \"torch.nn.Module\" or \"tf.Module\". Client-side. fedpredict_client_weight_predictions_torch Weight predictions to prioritize the most frequent classes in the newest data. Used when data is non-stationary and non-IID. The probabilities vectors \"Numpy array\". Client-side. fedpredict_server Compress the global model parameters for further sending to the clients The global model parameters as \"List[Numpy array]\". Server-side Methods fedpredict_client_torch This method includes two versions of FedPredict. Version 1: FedPredict presented in https://ieeexplore.ieee.org/abstract/document/10257293 Configuration: this version is the default. This method combines global and local parameters, providing both generalization and personalization. It also prevents the drop in the accuracy when new/untrained clients are evaluated Version 2: FedPredict-Dynamic Configuration: set 'dynamic=True' and inform the hyperparameters 'similarity' and 'fraction_of_classes'. This method has the same benefits as the v.1. However, differently from v.1, in the model combination process, it takes into account the similarity between the last and current datasets to weigh the combination and provide support for heterogeneous and non-stationary/dynamic data. Arguments Argument Description Type Default value local_model Local client's model. torch.nn.Module, required. - global_parameters The server's global parameters. list[np.array], required. - t The current round. int, required. - T The total rounds. int, required. - nt The number of rounds the client is without training. int, required. - M The list of indexes of the shared layers. list, optional. [] similarity The similarity between the old data (i.e., the one that the local model was previously trained on) and the new data. Used when Dynamic=True. float, optional 1 fraction_of_classes The fraction of classes in the local data. Used when Dynamic=True. float, optional. None filename The filename of the local model is saved. str, optional. '' knowledge_distillation If the model has knowledge distillation, then set True, to indicate that the global model parameters have to be combined with the student model bool, optional. False decompress Whether or not to decompress global model parameters in case a previous compression was applied. Only set True if using \"FedPredict_server\" and compressing the shared parameters. bool, optional. False dynamic If True, it uses the FedPredict-Dynamic. If False, it uses the traditional FedPredict. bool, optional. False Return The combined model of type 'torch.nn.Module'.","title":"Pytorch"},{"location":"api_reference_torch/#components","text":"FedPredict has three main components: Method Description Return Location fedpredict_client_torch / fedpredict_client_tf Combines global and local parameters. Used when data is non-ID either stationary or non-stationary. The combined model of type \"torch.nn.Module\" or \"tf.Module\". Client-side. fedpredict_client_weight_predictions_torch Weight predictions to prioritize the most frequent classes in the newest data. Used when data is non-stationary and non-IID. The probabilities vectors \"Numpy array\". Client-side. fedpredict_server Compress the global model parameters for further sending to the clients The global model parameters as \"List[Numpy array]\". Server-side","title":"Components"},{"location":"api_reference_torch/#methods","text":"","title":"Methods"},{"location":"api_reference_torch/#fedpredict_client_torch","text":"This method includes two versions of FedPredict. Version 1: FedPredict presented in https://ieeexplore.ieee.org/abstract/document/10257293 Configuration: this version is the default. This method combines global and local parameters, providing both generalization and personalization. It also prevents the drop in the accuracy when new/untrained clients are evaluated Version 2: FedPredict-Dynamic Configuration: set 'dynamic=True' and inform the hyperparameters 'similarity' and 'fraction_of_classes'. This method has the same benefits as the v.1. However, differently from v.1, in the model combination process, it takes into account the similarity between the last and current datasets to weigh the combination and provide support for heterogeneous and non-stationary/dynamic data.","title":"fedpredict_client_torch"},{"location":"api_reference_torch/#arguments","text":"Argument Description Type Default value local_model Local client's model. torch.nn.Module, required. - global_parameters The server's global parameters. list[np.array], required. - t The current round. int, required. - T The total rounds. int, required. - nt The number of rounds the client is without training. int, required. - M The list of indexes of the shared layers. list, optional. [] similarity The similarity between the old data (i.e., the one that the local model was previously trained on) and the new data. Used when Dynamic=True. float, optional 1 fraction_of_classes The fraction of classes in the local data. Used when Dynamic=True. float, optional. None filename The filename of the local model is saved. str, optional. '' knowledge_distillation If the model has knowledge distillation, then set True, to indicate that the global model parameters have to be combined with the student model bool, optional. False decompress Whether or not to decompress global model parameters in case a previous compression was applied. Only set True if using \"FedPredict_server\" and compressing the shared parameters. bool, optional. False dynamic If True, it uses the FedPredict-Dynamic. If False, it uses the traditional FedPredict. bool, optional. False","title":"Arguments"},{"location":"api_reference_torch/#return","text":"The combined model of type 'torch.nn.Module'.","title":"Return"},{"location":"quick_start/","text":"Quick start Simple usage At the client-side, after receiving the global model parameters in the prediction state, apply FedPredict as follows: t = 50 # current round T = 100 # total number of rounds nt = 3 # number of rounds since the last time the current client trained M = len(global_model_parameters) # the number of layers shared by the server # apply fedpredict combined_model = fedpredict_client_traditional(local_model=local_model, global_model_parameters=global_model_parameters, t=t, T=T, nt=nt, M=M) # Use the combined model to perform predictions over the input data y_hat = combined_model(X_test)","title":"Quick start"},{"location":"quick_start/#quick-start","text":"","title":"Quick start"},{"location":"quick_start/#simple-usage","text":"At the client-side, after receiving the global model parameters in the prediction state, apply FedPredict as follows: t = 50 # current round T = 100 # total number of rounds nt = 3 # number of rounds since the last time the current client trained M = len(global_model_parameters) # the number of layers shared by the server # apply fedpredict combined_model = fedpredict_client_traditional(local_model=local_model, global_model_parameters=global_model_parameters, t=t, T=T, nt=nt, M=M) # Use the combined model to perform predictions over the input data y_hat = combined_model(X_test)","title":"Simple usage"}]}